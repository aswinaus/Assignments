{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMkymOyudFjDLZeiLu8XZjB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinaus/Assignments/blob/main/Agent_RewardFunction_CosineSimilarity_GroundTruth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpEGNalHDvqV"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_experimental -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ul8zj9UhETD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Set the OpenAI API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] =  userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "rRxaZjaZEXWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "# Setup OpenAI Model and Embeddings used for indexing the documents\n",
        "Settings.llm = OpenAI(model='gpt-4o-mini', temperature=0.2)\n",
        "Settings.embed_model = OpenAIEmbedding(model='text-embedding-3-small')\n",
        "Settings.chunk_size = 1024"
      ],
      "metadata": {
        "id": "D38Nn8M1Eey2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive' # Input a data dir path from your mounted Google Drive"
      ],
      "metadata": {
        "id": "ZiGL3yLfF-hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "from llama_index.core import VectorStoreIndex, SummaryIndex"
      ],
      "metadata": {
        "id": "fY04X58OGE9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to avoid repeated calls to LLMs we can store the documents index and load it if present else create it\n",
        "PERSIST_INDEX_DIR = f\"/{data_dir}/RAG/data/\"\n",
        "def get_index(index_name, doc_file_path):\n",
        "  index = None\n",
        "  if not os.path.exists(f\"{PERSIST_INDEX_DIR}{index_name}/\"):\n",
        "    # Load the documents\n",
        "    documents = SimpleDirectoryReader(input_files=[doc_file_path]).load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # Store the index to disk\n",
        "    index.storage_context.persist(f\"{PERSIST_INDEX_DIR}{index_name}/\")\n",
        "  else: # Load index from disk\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=f\"{PERSIST_INDEX_DIR}{index_name}/\")\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "id": "VWrslIC4GJw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OECD guidelines documents for Transfer Pricing\n",
        "docs_OECD_guidelines = SimpleDirectoryReader(f\"{data_dir}/RAG/data/OECD/\").load_data()\n",
        "# Load OECD guidelines documents for Form990\n",
        "docs_Form990_guidelines = SimpleDirectoryReader(f\"{data_dir}/RAG/data/Form990/\").load_data()"
      ],
      "metadata": {
        "id": "f-ZbbEzxGSzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialise a storage context and use that for both Vector Index and Summary Index for OECD\n",
        "#split the OECD document into multiple nodes\n",
        "oecd_nodes = Settings.node_parser.get_nodes_from_documents(docs_OECD_guidelines)\n",
        "#split the Form990 document into multiple nodes\n",
        "form990_nodes = Settings.node_parser.get_nodes_from_documents(docs_Form990_guidelines)\n",
        "\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "storage_context.docstore.add_documents(oecd_nodes)\n",
        "storage_context.docstore.add_documents(form990_nodes)\n",
        "# Setup Vector and Summary Index from Storage Context\n",
        "summary_index = SummaryIndex(oecd_nodes, storage_context=storage_context)\n",
        "vector_index = VectorStoreIndex(oecd_nodes, storage_context=storage_context)\n",
        "\n",
        "# Setup Indices.In order to avoid repeated calls to LLMs we can store the documents index and load it if present else create it\n",
        "OECD_index = get_index(\"OECDTPGuidelines\",f\"{data_dir}/RAG/data/OECD/OECD_Transfer_Pricing_Guidelines.pdf\")\n",
        "form990_guidelines_index = get_index(\"Form990Guidelines\",f\"{data_dir}/RAG/data/Form990/Form990_Guidelines.pdf\")"
      ],
      "metadata": {
        "id": "hutBG-82GyeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "# Create the query engines\n",
        "OECD_engine = OECD_index.as_query_engine(similarity_top_k=3)\n",
        "form990_guidelines_engine = form990_guidelines_index.as_query_engine(similarity_top_k=3)\n",
        "# Create tools for the query engines\n",
        "OECD_query_tool = QueryEngineTool(\n",
        "                      query_engine=OECD_engine,\n",
        "                      metadata=ToolMetadata(\n",
        "                          name=\"OECD_QueryEngineTool_2022\",\n",
        "                          description=\"Provides information about Transfer Pricing Guidelines for Organization from OECD for year 2022\"\n",
        "                      )\n",
        "                    )\n",
        "\n",
        "Form990_query_tool = QueryEngineTool(\n",
        "                      query_engine=form990_guidelines_engine,\n",
        "                      metadata=ToolMetadata(\n",
        "                          name=\"form990_2022\",\n",
        "                          description=\"Provides information about Form990 filling guidelines for Non-Profit Organization only from the index which was set for Form990_Guidelines.pdf \"\n",
        "                      )\n",
        "                    )\n",
        "\n",
        "tools = [OECD_query_tool, Form990_query_tool]\n",
        "\n",
        "filing_engine = RouterQueryEngine(\n",
        "                      selector= LLMSingleSelector.from_defaults(),\n",
        "                      query_engine_tools=tools\n",
        "                      )"
      ],
      "metadata": {
        "id": "eF2CsXkzHBDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agentic Router RAG -\n",
        "from llama_index.agent.openai import OpenAIAgent\n",
        "agent = OpenAIAgent.from_tools(tools=tools, verbose=True)\n",
        "# Uncomment and use the below call for interactive session\n",
        "#agent.chat_repl()\n",
        "response = agent.chat(\"What is Form990 EZ and when should an organiaztion complete Form990 EZ form? And how is it different from Schedule H? Can you show the results in side by side comparison table with headers and also link to the document?\")\n",
        "print (response)"
      ],
      "metadata": {
        "id": "hlIsonI9Hlx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.agent.openai import OpenAIAssistantAgent\n",
        "agent = OpenAIAssistantAgent.from_new(\n",
        "          name = \"OECD and Form990 Agent\",\n",
        "          instructions= \"You are an assistant that provides answers to questions on OECD and Form990. And make sure the answers are retreived form the OECD and Form990 pdf's only. No data from open Internet. Whenever there is comparison make sure the results are in side by side comparison table with headers and add links to the document.\",\n",
        "          tools=tools,\n",
        "          verbose=True,\n",
        "          run_retrieve_sleep_time=1.0\n",
        "        )\n",
        "response = agent.chat(\"What does Articles 9 and 25 of the OECD Model Tax Convention state?\")\n",
        "print (response)"
      ],
      "metadata": {
        "id": "COLLlq4wJZZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"What does Articles 9 of the OECD Model Tax Convention state?\",\n",
        "             \"What does Articles 25 of the OECD Model Tax Convention state?\"]\n",
        "ground_truth = [\"addresses corresponding adjustments in transfer pricing\",\n",
        "                \"outlines the mutual agreement procedure, which resolves disputes related to the application of double tax conventions.\"]"
      ],
      "metadata": {
        "id": "iomDElQZ-_s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "rs5zdr0s_Zkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def cosine_similarity_reward(retrieved_context, ground_truth):\n",
        "    \"\"\"\n",
        "    Calculates a reward based on cosine similarity between the retrieved context\n",
        "    and the ground truth using TF-IDF vectorization.\n",
        "\n",
        "    Args:\n",
        "        retrieved_context (str): The text from the retrieved documents.\n",
        "        ground_truth (str): The ground truth text.\n",
        "\n",
        "    Returns:\n",
        "        float: A score between 0 and 1 representing the cosine similarity.\n",
        "    \"\"\"\n",
        "    # Handle empty strings\n",
        "    if not retrieved_context or not ground_truth:\n",
        "        return 0.0\n",
        "\n",
        "    # Create TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer().fit([retrieved_context, ground_truth])\n",
        "    vectors = vectorizer.transform([retrieved_context, ground_truth])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_score = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage (assuming 'contexts' and 'ground_truth' are defined):\n",
        "# combined_context = \" \".join(contexts[0]) # Combine retrieved contexts\n",
        "# reward = cosine_similarity_reward(combined_context, ground_truth[0])\n",
        "# print(f\"Cosine Similarity Reward: {reward}\")"
      ],
      "metadata": {
        "id": "wtwCsHlESzC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers  = []\n",
        "contexts = []\n",
        "cosine_similarity_rewards = [] # List to store cosine similarity rewards\n",
        "\n",
        "\n",
        "# traversing each question and passing into the chain to get answer from the system\n",
        "# Define the retriever from the OECD index\n",
        "retriever = OECD_index.as_retriever()\n",
        "\n",
        "for i, question in enumerate(questions):\n",
        "    response = agent.chat(question)\n",
        "    answers.append(response.response) # Extract the string response\n",
        "    retrieved_docs = retriever.retrieve(question)\n",
        "    context_texts = [docs.node.text for docs in retrieved_docs]\n",
        "    contexts.append(context_texts)\n",
        "\n",
        "    # Calculate cosine similarity reward\n",
        "    # Combine retrieved contexts into a single string for similarity calculation\n",
        "    combined_context = \" \".join(context_texts)\n",
        "    cosine_similarity_reward_score = cosine_similarity_reward(combined_context, ground_truth[i])\n",
        "    cosine_similarity_rewards.append(cosine_similarity_reward_score)\n",
        "\n",
        "\n",
        "# Preparing the dataset\n",
        "data = {\n",
        "    \"question\": questions,\n",
        "    \"answer\": answers,\n",
        "    \"ground_truth\": ground_truth,\n",
        "    \"contexts\": contexts, # Add the contexts to the dataset\n",
        "    \"cosine_similarity_reward\": cosine_similarity_rewards, # Add the cosine similarity rewards\n",
        "}\n",
        "\n",
        "# Convert dict to dataset\n",
        "dataset = Dataset.from_dict(data)\n",
        "dataset.to_pandas()"
      ],
      "metadata": {
        "id": "IMZHDx0B_dhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ragas --quiet\n",
        "import ragas"
      ],
      "metadata": {
        "id": "eHSrbhISAsaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "    ],\n",
        ")\n",
        "\n",
        "df = result.to_pandas()\n",
        "df"
      ],
      "metadata": {
        "id": "q2XWstAEAxO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#External API to showcase function calling\n",
        "from llama_index.core.tools import FunctionTool\n",
        "import requests\n",
        "from requests.auth import HTTPDigestAuth\n",
        "import json\n",
        "\n",
        "def call_form990API(param):\n",
        "  url = \"https://projects.propublica.org/nonprofits/api/v2/search.json?q=\"+param\n",
        "  apiResponse = requests.get(url, verify=True)\n",
        "  OrganizationData = json.loads(apiResponse.content)\n",
        "  return OrganizationData\n",
        "\n",
        "OrganizationData=call_form990API(\"north\")\n",
        "json_formatted_str = json.dumps(OrganizationData, indent=4)\n",
        "print(json_formatted_str)\n",
        "\n",
        "form990_function_tool = FunctionTool.from_defaults(fn=call_form990API)\n",
        "#tools = [call_form990API]\n",
        "# Create the Agent with our tools\n",
        "#agent = OpenAIAgent.from_tools(tools, verbose=True)\n",
        "#response = agent.query(\"North\")"
      ],
      "metadata": {
        "id": "IfHQA9GEWJUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reasoning and Act Agent\n",
        "from llama_index.core.agent import ReActAgent\n",
        "query_engine_tools = [OECD_query_tool, Form990_query_tool, form990_function_tool]\n",
        "agent = ReActAgent.from_tools(\n",
        "            tools= query_engine_tools,\n",
        "            verbose=True,\n",
        "            context=\"\"\"You are AI Tax Assistant. You will guide tax professionals for filling Form990 and answer queries related to Transfer Pricing based on the OECD guidelines.\n",
        "                      And make sure the answers are retreived form the OECD and Form990 pdf's only. No data from open Internet.\n",
        "                      Whenever there is comparison make sure the results are in side by side comparison table with headers and add links to the document.\"\"\"\n",
        "          )\n",
        "response = agent.query(\"Please compare and analyse Form990 Tax reporting process and Transfer Pricing methodologies used in identifying Intangibles used within Multinational Firms? If the analysis determines these process are for two different sectors then call the Form990 API with param north and include the results as part of the response?\")\n",
        "print (response)"
      ],
      "metadata": {
        "id": "bnslTf2WpmSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Oneshot Query Planning to demonstrate parallel processing\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "sub_question_query = \"Compare the Form990 Tax reporting process for Non Profit Organizations and Transfer Pricing methodologies used in identifying Intangibles used within a Multinational Firms?\"\n",
        "query_planning_engine = SubQuestionQueryEngine.from_defaults(\n",
        "                          query_engine_tools=tools,\n",
        "                          use_async=True\n",
        "                        )\n",
        "response = query_planning_engine.query(sub_question_query)\n",
        "print (response)"
      ],
      "metadata": {
        "id": "iQjP1_JkNJb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c49c6c24"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}